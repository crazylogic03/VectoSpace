{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "exp1-title",
            "metadata": {},
            "source": [
                "# Experiment 1 — Academic + Behavioral Features\n",
                "\n",
                "**Goal:** Predict `final_grade` using only academic and behavioral features.  \n",
                "**Features used:** `study_hours`, `attendance_percentage`, `study_method`, `math_score`, `science_score`, `english_score`  \n",
                "**Models:** Logistic Regression, Decision Tree  \n",
                "**Why these models?**\n",
                "- Logistic Regression → Simple baseline linear classifier\n",
                "- Decision Tree → Captures non-linear patterns and is easy to interpret"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Imports ---\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.tree import DecisionTreeClassifier\n",
                "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
                "\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')\n",
                "\n",
                "print('All imports loaded successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp1-load-header",
            "metadata": {},
            "source": [
                "## Step 1 — Load Cleaned Data\n",
                "We load the already preprocessed train and test CSVs from `data_analysis.ipynb`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-load-data",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the cleaned datasets\n",
                "train_df = pd.read_csv('../datasets/train_cleaned.csv')\n",
                "test_df  = pd.read_csv('../datasets/test_cleaned.csv')\n",
                "\n",
                "print('Training data shape :', train_df.shape)\n",
                "print('Test data shape     :', test_df.shape)\n",
                "print('\\nColumns available   :', list(train_df.columns))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp1-features-header",
            "metadata": {},
            "source": [
                "## Step 2 — Select Academic + Behavioral Features\n",
                "\n",
                "For Experiment 1 we use **only** these features:\n",
                "- `study_hours`, `attendance_percentage` (behavioral)\n",
                "- `math_score`, `science_score`, `english_score` (academic scores)\n",
                "- `study_method_*` columns (behavioral — one-hot encoded)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-select-features",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define the features for Experiment 1\n",
                "exp1_features = [\n",
                "    'study_hours',\n",
                "    'attendance_percentage',\n",
                "    'math_score',\n",
                "    'science_score',\n",
                "    'english_score',\n",
                "    'study_method_coaching',\n",
                "    'study_method_group study',\n",
                "    'study_method_mixed',\n",
                "    'study_method_notes',\n",
                "    'study_method_online videos',\n",
                "    'study_method_textbook'\n",
                "]\n",
                "\n",
                "# Separate features (X) and target (y)\n",
                "X_train = train_df[exp1_features]\n",
                "X_test  = test_df[exp1_features]\n",
                "\n",
                "y_train = train_df['final_grade']\n",
                "y_test  = test_df['final_grade']\n",
                "\n",
                "print('Experiment 1 feature count :', len(exp1_features))\n",
                "print('X_train shape              :', X_train.shape)\n",
                "print('X_test  shape              :', X_test.shape)\n",
                "print('\\nTarget distribution (train):')\n",
                "print(y_train.value_counts().sort_index())"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp1-train-header",
            "metadata": {},
            "source": [
                "## Step 3 — Train Models\n",
                "\n",
                "We train two classifiers:\n",
                "1. **Logistic Regression** — a linear baseline model\n",
                "2. **Decision Tree** — a non-linear model that can capture complex patterns"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-train-lr",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Model 1: Logistic Regression ---\n",
                "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
                "lr_model.fit(X_train, y_train)\n",
                "\n",
                "print('Logistic Regression trained successfully!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-train-dt",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Model 2: Decision Tree ---\n",
                "dt_model = DecisionTreeClassifier(random_state=42)\n",
                "dt_model.fit(X_train, y_train)\n",
                "\n",
                "print('Decision Tree trained successfully!')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp1-eval-header",
            "metadata": {},
            "source": [
                "## Step 4 — Evaluate Models\n",
                "\n",
                "We evaluate both models using:\n",
                "- **Accuracy** — overall correct predictions\n",
                "- **Precision** — how many predicted positives are actually positive\n",
                "- **Recall** — how many actual positives are correctly identified\n",
                "- **F1 Score** — harmonic mean of precision and recall (important for imbalanced classes)\n",
                "- **Confusion Matrix** — visual breakdown of predictions vs actual"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-predict",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate predictions on the test set\n",
                "lr_predictions = lr_model.predict(X_test)\n",
                "dt_predictions = dt_model.predict(X_test)\n",
                "\n",
                "print('Predictions generated for both models!')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-eval-lr",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Logistic Regression Evaluation ---\n",
                "print('=' * 50)\n",
                "print('LOGISTIC REGRESSION — Results')\n",
                "print('=' * 50)\n",
                "\n",
                "lr_accuracy = accuracy_score(y_test, lr_predictions)\n",
                "print(f'\\nAccuracy: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)')\n",
                "\n",
                "print('\\nClassification Report:')\n",
                "print(classification_report(y_test, lr_predictions))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-eval-dt",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Decision Tree Evaluation ---\n",
                "print('=' * 50)\n",
                "print('DECISION TREE — Results')\n",
                "print('=' * 50)\n",
                "\n",
                "dt_accuracy = accuracy_score(y_test, dt_predictions)\n",
                "print(f'\\nAccuracy: {dt_accuracy:.4f} ({dt_accuracy*100:.2f}%)')\n",
                "\n",
                "print('\\nClassification Report:')\n",
                "print(classification_report(y_test, dt_predictions))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-confusion-matrix",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Confusion Matrices (side by side) ---\n",
                "grade_labels = ['f(0)', 'e(1)', 'd(2)', 'c(3)', 'b(4)', 'a(5)']\n",
                "\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "# Logistic Regression confusion matrix\n",
                "ConfusionMatrixDisplay.from_predictions(\n",
                "    y_test, lr_predictions,\n",
                "    display_labels=grade_labels,\n",
                "    cmap='Blues',\n",
                "    ax=axes[0]\n",
                ")\n",
                "axes[0].set_title('Logistic Regression')\n",
                "\n",
                "# Decision Tree confusion matrix\n",
                "ConfusionMatrixDisplay.from_predictions(\n",
                "    y_test, dt_predictions,\n",
                "    display_labels=grade_labels,\n",
                "    cmap='Greens',\n",
                "    ax=axes[1]\n",
                ")\n",
                "axes[1].set_title('Decision Tree')\n",
                "\n",
                "plt.suptitle('Experiment 1 — Confusion Matrices', fontsize=14, fontweight='bold')\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp1-compare-header",
            "metadata": {},
            "source": [
                "## Step 5 — Compare Results\n",
                "\n",
                "Let's put both models side-by-side to see which one performs better on academic + behavioral features."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "exp1-compare-table",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Calculate weighted F1 scores for both models\n",
                "lr_f1 = f1_score(y_test, lr_predictions, average='weighted')\n",
                "dt_f1 = f1_score(y_test, dt_predictions, average='weighted')\n",
                "\n",
                "# Build comparison table\n",
                "comparison = pd.DataFrame({\n",
                "    'Model': ['Logistic Regression', 'Decision Tree'],\n",
                "    'Accuracy': [round(lr_accuracy, 4), round(dt_accuracy, 4)],\n",
                "    'Weighted F1': [round(lr_f1, 4), round(dt_f1, 4)]\n",
                "})\n",
                "\n",
                "print('Experiment 1 — Results Comparison')\n",
                "print('Feature Set: Academic + Behavioral')\n",
                "print('=' * 55)\n",
                "print(comparison.to_string(index=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "exp1-observations",
            "metadata": {},
            "source": [
                "## Observations\n",
                "\n",
                "- **Academic scores** (`math_score`, `science_score`, `english_score`) are strong predictors of `final_grade`.\n",
                "- **Study method** being one-hot encoded gives both models clear categorical signals.\n",
                "- **Logistic Regression** works as a good baseline but may struggle with non-linear grade boundaries.\n",
                "- **Decision Tree** can capture more complex patterns but risks overfitting on training data.\n",
                "- In the next experiments, we will add more features to see if performance improves."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "base",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}